import os
import sys
import requests
import pandas as pd
from PIL import Image
from io import BytesIO
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ëª¨ë“ˆ ì„í¬íŠ¸
from src.core import clip_processor, hypernym_extractor
from src.external import search_api_client, search_with_clip, sd_generator

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
API_CONFIG = {
    "GOOGLE_API_KEY": os.getenv("GOOGLE_API_KEY"),
    "GOOGLE_CX": os.getenv("GOOGLE_CX"),
}
GENERATED_IMAGES_DIR = "generated_images"
os.makedirs(GENERATED_IMAGES_DIR, exist_ok=True)

# ==========================================
# â–¶ ì‹¤í—˜ ë°ì´í„°: ê³¼ì¼(Group 1) + ë™ë¬¼(Group 2) í˜¼í•©
# ==========================================
cross_group_inputs = [
    {"text": "apple", "image": "./data/apple.png"},
    {"text": "banana", "image": "./data/banana.png"},
    {"text": "dog", "image": "./data/dog.png"},
    {"text": "cat", "image": "./data/cat.png"}
]

def load_image_content(path):
    try:
        return Image.open(path).convert("RGB")
    except Exception as e:
        print(f"Error loading {path}: {e}")
        return None

def calculate_score(text, image_obj, processor, model):
    if image_obj is None: return 0.0
    try:
        text_feat = clip_processor.get_text_features([text], processor, model)
        img_feat = clip_processor.get_image_features([image_obj], processor, model)
        return round((text_feat @ img_feat.T).item(), 4)
    except:
        return 0.0

def visualize_and_save(mode, hypernym, clip_components):
    save_path = None
    try:
        if mode == "Basic Search":
            url = search_api_client.search_image(hypernym, API_CONFIG)
            return url # URL ë°˜í™˜
        
        elif mode == "CLIP Reranking":
            url = search_with_clip.search_and_rerank_image(hypernym, API_CONFIG, clip_components)
            return url # URL ë°˜í™˜
            
        elif mode == "Generative":
            # í•œê³„ì  ì‹¤í—˜ìš©ì´ë¯€ë¡œ íŒŒì¼ëª…ì„ ëª…í™•íˆ êµ¬ë¶„ (cross_generated.png)
            path = sd_generator.generate_image_from_text(hypernym, GENERATED_IMAGES_DIR)
            if path:
                # íŒŒì¼ëª… ë³€ê²½ (ë®ì–´ì“°ê¸° ë°©ì§€ ì•„ë‹˜, ê·¸ëƒ¥ íŠ¹ì • ì´ë¦„ìœ¼ë¡œ ì €ì¥)
                new_path = os.path.join(GENERATED_IMAGES_DIR, "cross_group_generated.png")
                import shutil
                shutil.move(path, new_path)
                return new_path
    except Exception as e:
        print(f"Visualization Error ({mode}): {e}")
    return None

def run_cross_group_experiment():
    print(">>> âš ï¸ [Cross-Group Limit Test] ì´ì¢… ë„ë©”ì¸ ê²°í•© ì‹¤í—˜ ì‹œì‘")
    print(">>> Inputs: Apple, Banana (Fruit) + Dog, Cat (Animal)")
    
    processor, model = clip_processor.load_clip_model()
    clip_components = (processor, model)

    # 1. ë°ì´í„° ë¡œë“œ
    imgs = [load_image_content(i['image']) for i in cross_group_inputs]
    texts = [i['text'] for i in cross_group_inputs]
    
    if any(i is None for i in imgs):
        print("ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    # 2. ìƒìœ„ì–´ ì¶”ë¡  (ì˜ˆìƒ: organism, living thing, whole ë“± ì•„ì£¼ ì¶”ìƒì ì¸ ë‹¨ì–´)
    print("\n[1] ìƒìœ„ì–´ ì¶”ë¡  ì¤‘...")
    hypernym, score = hypernym_extractor.determine_best_hypernym(
        imgs, texts, clip_components
    )
    print(f"   ğŸ‘‰ ë„ì¶œëœ ìƒìœ„ì–´: '{hypernym}' (Score: {score:.4f})")
    print("   (ì˜ˆìƒ ë¶„ì„: ì„œë¡œ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ê°€ ì„ì—¬ì„œ ë§¤ìš° í¬ê´„ì ì¸ ë‹¨ì–´ê°€ ë‚˜ì™”ì„ ê²ƒì„)")

    # 3. 3ê°€ì§€ ëª¨ë“œë¡œ ì‹œê°í™”
    modes = ["Basic Search", "CLIP Reranking", "Generative"]
    results = []

    print("\n[2] ì‹œê°í™” ë° ì ìˆ˜ ì¸¡ì •")
    for mode in modes:
        print(f"   Running {mode}...")
        result_src = visualize_and_save(mode, hypernym, clip_components)
        
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì ìˆ˜ ê³„ì‚°
        if result_src and result_src.startswith("http"):
             response = requests.get(result_src, timeout=10)
             res_img = Image.open(BytesIO(response.content)).convert("RGB")
        elif result_src:
             res_img = Image.open(result_src).convert("RGB")
        else:
             res_img = None

        final_score = calculate_score(hypernym, res_img, processor, model)
        print(f"     -> Score: {final_score} / Source: {result_src}")
        
        results.append({
            "Mode": mode,
            "Hypernym": hypernym,
            "CLIP Score": final_score,
            "Source": result_src
        })

    # ê²°ê³¼ ì €ì¥
    df = pd.DataFrame(results)
    print("\n=== [ì´ì¢… ë„ë©”ì¸ ì‹¤í—˜ ê²°ê³¼] ===")
    print(df)
    df.to_csv("cross_group_results.csv", index=False)

if __name__ == "__main__":
    run_cross_group_experiment()