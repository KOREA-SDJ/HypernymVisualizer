import os
import sys
import torch
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import requests
from io import BytesIO
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì • (ëª¨ë“ˆ ì„í¬íŠ¸ë¥¼ ìœ„í•´)
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ê¸°ì¡´ í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸
from src.core import clip_processor, hypernym_extractor
from src.external import search_api_client, search_with_clip, sd_generator

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
API_CONFIG = {
    "GOOGLE_API_KEY": os.getenv("GOOGLE_API_KEY"),
    "GOOGLE_CX": os.getenv("GOOGLE_CX"),
}
GENERATED_IMAGES_DIR = "generated_images"
os.makedirs(GENERATED_IMAGES_DIR, exist_ok=True)

# ==========================================
# â–¶ 1. ì‹¤í—˜ ë°ì´í„°ì…‹ ì„¤ì • (5ê°œ ê·¸ë£¹)
# TODO: ì‹¤ì œ í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œë¡œ ë°˜ë“œì‹œ ìˆ˜ì •í•´ì£¼ì„¸ìš”!
# ==========================================
experiment_groups = [
    {
        "name": "Group 1 (Fruit)",
        "texts": ["apple", "banana", "grape"],
        "images": ["./data/apple.png", "./data/banana.png", "./data/grape.png"] 
    },
    {
        "name": "Group 2 (Animal)",
        "texts": ["dog", "cat", "tiger"],
        "images": ["./data/dog.png", "./data/cat.png", "./data/tiger.png"]
    },
    {
        "name": "Group 3 (Vehicle)",
        "texts": ["car", "bus", "train"],
        "images": ["./data/car.png", "./data/bus.png", "./data/train.png"]
    },
    {
        "name": "Group 4 (Furniture)",
        "texts": ["chair", "sofa", "bed"],
        "images": ["./data/chair.png", "./data/sofa.png", "./data/bed.png"]
    },
    {
        "name": "Group 5 (Instrument)",
        "texts": ["guitar", "piano", "drum"],
        "images": ["./data/guitar.png", "./data/piano.png", "./data/drum.png"]
    }
]

# ==========================================
# â–¶ 2. í—¬í¼ í•¨ìˆ˜ ì •ì˜
# ==========================================
def load_image_from_path_or_url(path_or_url):
    """ë¡œì»¬ ê²½ë¡œ ë˜ëŠ” URLì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        if path_or_url.startswith("http"):
            response = requests.get(path_or_url, timeout=10)
            image = Image.open(BytesIO(response.content)).convert("RGB")
        else:
            image = Image.open(path_or_url).convert("RGB")
        return image
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {path_or_url} - Error: {e}")
        return None

def calculate_single_clip_score(text, image, processor, model):
    """ë‹¨ì¼ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ CLIP Scoreë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    if image is None:
        return 0.0
    try:
        text_feat = clip_processor.get_text_features([text], processor, model)
        img_feat = clip_processor.get_image_features([image], processor, model)
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = (text_feat @ img_feat.T).item()
        return round(similarity, 4)
    except Exception as e:
        print(f"ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 0.0

# ==========================================
# â–¶ 3. ë©”ì¸ ì‹¤í—˜ ì‹¤í–‰ í•¨ìˆ˜
# ==========================================
def run_experiments():
    print(">>> ğŸ§ª ì‹¤í—˜ ì‹œì‘: ëª¨ë¸ ë¡œë”© ì¤‘... (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦½ë‹ˆë‹¤)")
    processor, model = clip_processor.load_clip_model()
    clip_components = (processor, model)
    
    results = [] # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸

    for group in experiment_groups:
        print(f"\n--- [Testing Group: {group['name']}] ---")
        
        # 1) ì…ë ¥ ì´ë¯¸ì§€ ë¡œë“œ
        input_images = []
        for path in group['images']:
            img = load_image_from_path_or_url(path)
            if img: input_images.append(img)
        
        if len(input_images) < 2:
            print(f"ê²½ê³ : {group['name']} ê·¸ë£¹ì˜ ì´ë¯¸ì§€ê°€ ë¶€ì¡±í•˜ì—¬ ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        # 2) ìƒìœ„ì–´ ì¶”ë¡ 
        print("Step 1: ìƒìœ„ì–´ ì¶”ë¡  ì¤‘...")
        hypernym, _ = hypernym_extractor.determine_best_hypernym(
            input_images=input_images,
            input_texts=group['texts'],
            clip_model_components=clip_components
        )
        print(f"â–¶ ê²°ì •ëœ ìƒìœ„ì–´: '{hypernym}'")

        # 3) 3ê°€ì§€ ëª¨ë¸ ì‹¤í–‰ ë° í‰ê°€
        modes = [
            ("Basic Search", search_api_client.search_image, {"api_config": API_CONFIG}),
            ("CLIP Reranking", search_with_clip.search_and_rerank_image, {"api_config": API_CONFIG, "clip_components": clip_components}),
            ("Generative", sd_generator.generate_image_from_text, {"output_dir": GENERATED_IMAGES_DIR})
        ]

        for mode_name, func, kwargs in modes:
            print(f"Step 2: Running mode [{mode_name}]...")
            result_path_or_url = None
            try:
                # ê° ëª¨ë“œ í•¨ìˆ˜ ì‹¤í–‰
                if mode_name == "Generative":
                     result_path_or_url = func(hypernym, **kwargs)
                else:
                     result_path_or_url = func(hypernym, **kwargs)
            except Exception as e:
                print(f"Error in {mode_name}: {e}")

            # ê²°ê³¼ ì´ë¯¸ì§€ ë¡œë“œ ë° ì ìˆ˜ ê³„ì‚°
            result_image = load_image_from_path_or_url(result_path_or_url) if result_path_or_url else None
            score = calculate_single_clip_score(hypernym, result_image, processor, model)
            
            print(f"  -> Result Score: {score}")

            # ê²°ê³¼ ì €ì¥
            results.append({
                "Group": group['name'],
                "Hypernym": hypernym,
                "Model": mode_name,
                "CLIP Score": score
            })

    return results

# ==========================================
# â–¶ 4. ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜
# ==========================================
def visualize_results(df):
    print("\n>>> ğŸ“Š ê²°ê³¼ ì‹œê°í™” ìƒì„± ì¤‘...")
    sns.set_theme(style="whitegrid")
    
    plt.figure(figsize=(12, 7))
    
    # ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„± (ê·¸ë£¹ë³„, ëª¨ë¸ë³„ ë¹„êµ)
    barplot = sns.barplot(
        data=df,
        x="Group",
        y="CLIP Score",
        hue="Model",
        palette="viridis" # ìƒ‰ìƒ í…Œë§ˆ (deep, muted, pastel, bright, dark, colorblind, viridis ë“±)
    )

    # ê·¸ë˜í”„ ê¾¸ë¯¸ê¸°
    plt.title("Quantitative Comparison of CLIP Scores by Group and Model", fontsize=16, fontweight='bold')
    plt.ylabel("CLIP Score (Cosine Similarity)", fontsize=12)
    plt.xlabel("Experiment Groups", fontsize=12)
    plt.xticks(rotation=15)
    plt.legend(title='Model Type', title_fontsize='12', loc='upper right')
    plt.ylim(0.15, 0.35) # Yì¶• ë²”ìœ„ ì„¤ì • (ì ìˆ˜ ë¶„í¬ì— ë”°ë¼ ì¡°ì ˆ ê°€ëŠ¥)

    # ë§‰ëŒ€ ìœ„ì— ì ìˆ˜ í‘œì‹œ
    for container in barplot.containers:
        barplot.bar_label(container, fmt='%.4f', padding=3, fontsize=10)

    plt.tight_layout()
    plt.savefig("experiment_result_graph.png", dpi=300) # ê·¸ë˜í”„ ì´ë¯¸ì§€ ì €ì¥
    print("ê·¸ë˜í”„ê°€ 'experiment_result_graph.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    plt.show() # í™”ë©´ì— í‘œì‹œ

# ==========================================
# â–¶ ë©”ì¸ ì‹¤í–‰ ë¸”ë¡
# ==========================================
if __name__ == "__main__":
    # 1. ì‹¤í—˜ ì‹¤í–‰
    experiment_results = run_experiments()
    
    if experiment_results:
        # 2. ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        df = pd.DataFrame(experiment_results)
        
        print("\n\n=== [ìµœì¢… ì‹¤í—˜ ê²°ê³¼ ë°ì´í„°] ===")
        print(df)
        
        # CSV íŒŒì¼ë¡œ ì €ì¥ (ë…¼ë¬¸ í‘œ ì‘ì„±ìš©)
        df.to_csv("final_experiment_results.csv", index=False)
        print("\nê²°ê³¼ ë°ì´í„°ê°€ 'final_experiment_results.csv'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # 3. í‰ê·  ì ìˆ˜ ê³„ì‚° ë° ì¶œë ¥
        print("\n=== [ëª¨ë¸ë³„ í‰ê·  CLIP Score] ===")
        avg_scores = df.groupby("Model")["CLIP Score"].mean().reset_index()
        print(avg_scores)
        
        # 4. ì‹œê°í™” ì‹¤í–‰
        visualize_results(df)
    else:
        print("ì‹¤í—˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")